---
title: "[ML][GAN][paper] pix2pix"
excerpt: ""
date: 2020-04-21
categories:
  - ML
tags:
teaser: /assets/images/teaser/neural_network.jpg
toc: true
toc_label: "Table of contents"
toc_icon: "heart"  # corresponding Font Awesome icon name (without fa prefix)
toc_sticky: true
classes: wide
---

Goal : pix2pix 이해하기
---

# Abstract 

conditional adversarial net은 범용 목적의 image2image 변환 문제에 대한 해답이 될 수 있습니다. 이 네트워크는 입력 이미지에서 출력 이미지로의 mapping을 배우는 것뿐만 아니라, 이 mapping의 loss function을 배웁니다. 이 말은 단순히 training data로부터 mappipng을 배우고 암기하는 것이 아니라, loss function을 학습함으로서 새로운 데이터에 적용할 수 있음을 의미합니다. 게다가 이미 전세계의 많은 사용자들이 본 논문에 기반한 pix2pix app을 사용했기 때문에 parameter 수정이 필요없이 다양한 문제에 적용할 수 있음을 보여주고 있습니다. 따라서 우리는 loss function을 hand-engineer하지 않고 괜찮은 결과를 얻을 수 있습니다.  

# Introduction

많은 image 처리 문제는 input image를 output image로 변환하는 것으로 표현될 수 있습니다. 언어 자동 변역과 비슷하게, 우리는 충분한 데이터가 주어졌을 때 image2image 변환을 정의할 수 있습니다. 전통적인 방법에서는 pixel2pixel 변환이라는 동일한 조건에서도 각각을 특별한 메커니즘으로 다루었습니다. 본 논문의 목표는 이러한 문제를 해결한 공통의 framework를 개발하는 것입니다.  

CNN은 이미 많은 분야에서 공통적으로 사용되는 net가 되었습니다. CNN은 loss function을 최소화하는 방법을 배웁니다. 하지만 학습 과정이 매우 자동적으로 진행될 수 있음에도 사람의 수동적인 노력이 많이 수반되어야 합니다. 바꿔말하면 우리는 아직 CNN에게 어떤 것을 최소화해야하는지 알려주어야 합니다. 그리고 사람은 어떤 것을 최소화할지 매우 조심스럽게 선택해야합니다. 만약 우리가 CNN에게 유클리디안 거리를 최소화하라고 알려준다면 굉장히 blur한 이미지를 얻게 됩니다. 왜냐하면 유클리디안 거리는 가능한 모든 output을 평균내기 때문에 blurring을 야기합니다. 

만약 사실과 구별되지 않도록 만드는 것만이 유일한 목표라면, 이 목표를 이루기 위한 loss function을 학습할 것입니다. 이 과정은 GAN에 의해서 진행되었고, 더이상 blur한 이미지가 도출될 가능성은 작아집니다. GAN은 데이터에 따라서 적응할 loss를 학습하기 때문에 전통적인 다양한 문제에 적용될 수 있습니다.  

본 논문에서는 Conditional GAN을 사용합니다.  CGAN은 conditional generator model을 학습합니다. 이 특성 덕분에 사람이 적절한 input image을 넣어주면 generator는 이에 따른 output image를 생성할 수 있습니다. 우리의 첫 번째 기여는 CGAN이 얼마나 많은 분야에서 적용될 수 있는지 증명하는 것입니다. 두 번째 기여는 좋은 결과를 내는 간단한 framework를 제안하고 몇 가지 중요한 대안들에 대해서 분석하는 것입니다.

# Related Work

## Stuctured losses for image modeling

image2image 변환 문는 주로 per-pixel classification/regression 문제로 공식화 됩니다. 이 공식들은 output space를 unstructured로 간주하는데, 이는 각각의 output pixel들이 conditionally 모든 input image들과 독립적이라는 의미입니다(인접한 픽셀간에는 서로 영향을 미치지 않는 독립적인 관계). CGAN은 이와 다르게 structued loss를 학습합니다. structured loss는 output의 'joint configuration(연관 관계)' penalize합니다. 연관 관계에 있는 pixel들에 대해서 패널티를 부과하는 것은 그들의 관계를 인정하고 이에 대한 대응을 취하는 것으로 생각할 수 있습니다.(여기서 패널티는 output과 taret의 차이를 줄이기 위한 loss를 통해서 주어집니다) 정리하자면 픽셀들 사이의 연관관계를 고려하기 때문에 유클리디안 거리를 최소화하는 CNN보다 더 좋은 결과를 얻을 수 있게 됩니다.  

Loss를 계산하는 방법은 논문에 따라서  

1. conditional random fields
1. the SSIM metric
1. feature matching
1. nonparametric losses
1. convolutional pseudo-prior
1. losses based on mathcin covariance statistics

의 방법을 사용합니다.  

## CGANs

지금까지 수 많은 conditional GAN들이 discrete labels, text, image등에 대해서 적용되었습니다. 또다른 논문에서는 GAN을 un-condition한 환경에서 L2 regression과 같은 다른 용어들에 기대면서 output이 input에 의해서 condition되도록 강제했습니다.  

우리의 framework는 두 가지 부분에서 기존의 net과 다릅니다. 첫 째, 특정 앱에 목적을 두지 않는 범용 framework를 지향합니다. 둘 째, generator에서 U-net에 기초한 아키텍쳐를 사용하였습니다. 그리고 Discriminator에는 convolutional PatchGAN classifier를 사용하였습니다. 이는 image를 patch의 크기에 따라서 penalize하는 특징을 가집니다. 







